{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f4b78d1-bd7b-4490-887e-16ca4256d979",
   "metadata": {},
   "source": [
    "Digit Recoginization ML Model using tenserflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c21e972-bc82-4718-828d-dd08d19324f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a35b622b-ce23-4414-87f9-4eff0c2e413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist    ##loding digit dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c5c17b-dfef-47db-9fdf-e8634f226474",
   "metadata": {},
   "source": [
    "Spliting data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aabaf0ce-1f7f-4881-96c5-b202fa05ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "107d0ae0-2010-45d3-ba03-61894b5f5023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) x_train dtype: uint8 \n",
      " y_train shape: (60000,) y_train dtype: uint8\n",
      "x_test shape: (10000, 28, 28) x_test dtype: uint8 \n",
      " y_test shape: (10000,) y_test dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:',x_train.shape,'x_train dtype:',x_train.dtype,'\\n y_train shape:',y_train.shape,'y_train dtype:',y_train.dtype)\n",
    "print('x_test shape:',x_test.shape,'x_test dtype:',x_test.dtype,'\\n y_test shape:',y_test.shape,'y_test dtype:',y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e43b0fdc-6574-4738-822a-0a99aecb9bea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b3fcfeb-9a18-4ae9-ba19-2d88ace6caa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "plt.title(y_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c740f38-fece-46dc-9b27-736bd258f8a5",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17000a7c-cc71-4c95-945c-c7985932f788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00393124, 0.02332955, 0.02620568,\n",
       "        0.02625207, 0.17420356, 0.17566281, 0.28629534, 0.05664824,\n",
       "        0.51877786, 0.71632322, 0.77892406, 0.89301644, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05780486, 0.06524513,\n",
       "        0.16128198, 0.22713296, 0.22277047, 0.32790981, 0.36833534,\n",
       "        0.3689874 , 0.34978968, 0.32678448, 0.368094  , 0.3747499 ,\n",
       "        0.79066747, 0.67980478, 0.61494005, 0.45002403, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12250613, 0.45858525, 0.45852825,\n",
       "        0.43408872, 0.37314701, 0.33153488, 0.32790981, 0.36833534,\n",
       "        0.3689874 , 0.34978968, 0.32420121, 0.15214552, 0.17865984,\n",
       "        0.25626376, 0.1573102 , 0.12298801, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04500225, 0.4219755 , 0.45852825,\n",
       "        0.43408872, 0.37314701, 0.33153488, 0.32790981, 0.28826244,\n",
       "        0.26543758, 0.34149427, 0.31128482, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.1541463 , 0.28272888,\n",
       "        0.18358693, 0.37314701, 0.33153488, 0.26569767, 0.01601458,\n",
       "        0.        , 0.05945042, 0.19891229, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.0253731 ,\n",
       "        0.00171577, 0.22713296, 0.33153488, 0.11664776, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20500962, 0.33153488, 0.24625638, 0.00291174,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01622378, 0.24897876, 0.32790981, 0.10191096,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04586451, 0.31235677, 0.32757096,\n",
       "        0.23335172, 0.14931733, 0.00129164, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.10498298, 0.34940902,\n",
       "        0.3689874 , 0.34978968, 0.15370495, 0.04089933, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06551419,\n",
       "        0.27127137, 0.34978968, 0.32678448, 0.245396  , 0.05882702,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02333517, 0.12857881, 0.32549285, 0.41390126, 0.40743158,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32161793, 0.41390126, 0.54251585,\n",
       "        0.20001074, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06697006,\n",
       "        0.18959827, 0.25300993, 0.32678448, 0.41390126, 0.45100715,\n",
       "        0.00625034, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.05110617, 0.19182076, 0.33339444,\n",
       "        0.3689874 , 0.34978968, 0.32678448, 0.40899334, 0.39653769,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04117838, 0.16813739, 0.28960162, 0.32790981, 0.36833534,\n",
       "        0.3689874 , 0.34978968, 0.25961929, 0.12760592, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.04431706, 0.11961607,\n",
       "        0.36545809, 0.37314701, 0.33153488, 0.32790981, 0.36833534,\n",
       "        0.28877275, 0.111988  , 0.00258328, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.05298497, 0.42752138, 0.4219755 , 0.45852825,\n",
       "        0.43408872, 0.37314701, 0.33153488, 0.25273681, 0.11646967,\n",
       "        0.01312603, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.37491383,\n",
       "        0.56222061, 0.66525569, 0.63253163, 0.48748768, 0.45852825,\n",
       "        0.43408872, 0.359873  , 0.17428513, 0.01425695, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.92705966,\n",
       "        0.82698729, 0.74473314, 0.63253163, 0.4084877 , 0.24466922,\n",
       "        0.22648107, 0.02359823, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train,axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test,axis=1)\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4866c67c-4dae-4ca3-9380-04973876dbaf",
   "metadata": {},
   "source": [
    "Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbd25e6d-a5dd-4291-b954-4f6dda966331",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c36068d7-dfc4-4754-9e74-e5ff42cb49c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(tf.keras.layers.Flatten(input_shape = (28,28) ) )\n",
    "model.add(tf.keras.layers.Dense(16, activation = 'relu') )\n",
    "model.add(tf.keras.layers.Dropout(0.2) )\n",
    "model.add(tf.keras.layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efe707a0-c122-47ee-afbf-87cf9874538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer ='adam', loss ='SparseCategoricalCrossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf84e3-3dde-4a61-b2e5-d544f4d8c53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.2520 - loss: 2.1645 - val_accuracy: 0.7015 - val_loss: 1.5542\n",
      "Epoch 2/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6122 - loss: 1.4881 - val_accuracy: 0.8134 - val_loss: 0.9999\n",
      "Epoch 3/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7047 - loss: 1.0857 - val_accuracy: 0.8514 - val_loss: 0.7216\n",
      "Epoch 4/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7440 - loss: 0.8763 - val_accuracy: 0.8726 - val_loss: 0.5664\n",
      "Epoch 5/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7765 - loss: 0.7439 - val_accuracy: 0.8845 - val_loss: 0.4856\n",
      "Epoch 6/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8040 - loss: 0.6576 - val_accuracy: 0.8936 - val_loss: 0.4363\n",
      "Epoch 7/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8152 - loss: 0.6124 - val_accuracy: 0.8977 - val_loss: 0.4026\n",
      "Epoch 8/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8273 - loss: 0.5751 - val_accuracy: 0.9009 - val_loss: 0.3792\n",
      "Epoch 9/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8338 - loss: 0.5460 - val_accuracy: 0.9035 - val_loss: 0.3613\n",
      "Epoch 10/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8348 - loss: 0.5346 - val_accuracy: 0.9070 - val_loss: 0.3472\n",
      "Epoch 11/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8424 - loss: 0.5185 - val_accuracy: 0.9103 - val_loss: 0.3360\n",
      "Epoch 12/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8482 - loss: 0.4964 - val_accuracy: 0.9117 - val_loss: 0.3265\n",
      "Epoch 13/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8517 - loss: 0.4831 - val_accuracy: 0.9132 - val_loss: 0.3198\n",
      "Epoch 14/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8518 - loss: 0.4737 - val_accuracy: 0.9138 - val_loss: 0.3126\n",
      "Epoch 15/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 0.4622 - val_accuracy: 0.9154 - val_loss: 0.3077\n",
      "Epoch 16/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8583 - loss: 0.4591 - val_accuracy: 0.9173 - val_loss: 0.3009\n",
      "Epoch 17/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8605 - loss: 0.4482 - val_accuracy: 0.9179 - val_loss: 0.2958\n",
      "Epoch 18/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8622 - loss: 0.4460 - val_accuracy: 0.9187 - val_loss: 0.2929\n",
      "Epoch 19/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8621 - loss: 0.4397 - val_accuracy: 0.9187 - val_loss: 0.2886\n",
      "Epoch 20/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8693 - loss: 0.4139 - val_accuracy: 0.9193 - val_loss: 0.2856\n",
      "Epoch 21/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8681 - loss: 0.4219 - val_accuracy: 0.9198 - val_loss: 0.2815\n",
      "Epoch 22/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8699 - loss: 0.4173 - val_accuracy: 0.9201 - val_loss: 0.2798\n",
      "Epoch 23/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8704 - loss: 0.4186 - val_accuracy: 0.9222 - val_loss: 0.2760\n",
      "Epoch 24/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8755 - loss: 0.4037 - val_accuracy: 0.9224 - val_loss: 0.2731\n",
      "Epoch 25/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8743 - loss: 0.4032 - val_accuracy: 0.9236 - val_loss: 0.2703\n",
      "Epoch 26/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8725 - loss: 0.4036 - val_accuracy: 0.9240 - val_loss: 0.2675\n",
      "Epoch 27/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8768 - loss: 0.3966 - val_accuracy: 0.9255 - val_loss: 0.2659\n",
      "Epoch 28/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8746 - loss: 0.3998 - val_accuracy: 0.9243 - val_loss: 0.2646\n",
      "Epoch 29/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8773 - loss: 0.3895 - val_accuracy: 0.9255 - val_loss: 0.2623\n",
      "Epoch 30/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8820 - loss: 0.3780 - val_accuracy: 0.9255 - val_loss: 0.2596\n",
      "Epoch 31/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8783 - loss: 0.3920 - val_accuracy: 0.9267 - val_loss: 0.2590\n",
      "Epoch 32/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8777 - loss: 0.3850 - val_accuracy: 0.9269 - val_loss: 0.2568\n",
      "Epoch 33/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8787 - loss: 0.3823 - val_accuracy: 0.9274 - val_loss: 0.2541\n",
      "Epoch 34/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8798 - loss: 0.3781 - val_accuracy: 0.9267 - val_loss: 0.2539\n",
      "Epoch 35/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8803 - loss: 0.3774 - val_accuracy: 0.9277 - val_loss: 0.2520\n",
      "Epoch 36/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8823 - loss: 0.3770 - val_accuracy: 0.9280 - val_loss: 0.2493\n",
      "Epoch 37/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8848 - loss: 0.3651 - val_accuracy: 0.9285 - val_loss: 0.2496\n",
      "Epoch 38/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8872 - loss: 0.3640 - val_accuracy: 0.9292 - val_loss: 0.2475\n",
      "Epoch 39/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8848 - loss: 0.3656 - val_accuracy: 0.9286 - val_loss: 0.2454\n",
      "Epoch 40/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8857 - loss: 0.3625 - val_accuracy: 0.9298 - val_loss: 0.2445\n",
      "Epoch 41/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8847 - loss: 0.3664 - val_accuracy: 0.9305 - val_loss: 0.2419\n",
      "Epoch 42/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8844 - loss: 0.3655 - val_accuracy: 0.9305 - val_loss: 0.2416\n",
      "Epoch 43/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8835 - loss: 0.3608 - val_accuracy: 0.9316 - val_loss: 0.2403\n",
      "Epoch 44/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8846 - loss: 0.3585 - val_accuracy: 0.9311 - val_loss: 0.2386\n",
      "Epoch 45/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8847 - loss: 0.3643 - val_accuracy: 0.9312 - val_loss: 0.2387\n",
      "Epoch 46/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8889 - loss: 0.3518 - val_accuracy: 0.9321 - val_loss: 0.2376\n",
      "Epoch 47/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8865 - loss: 0.3478 - val_accuracy: 0.9324 - val_loss: 0.2351\n",
      "Epoch 48/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8911 - loss: 0.3423 - val_accuracy: 0.9333 - val_loss: 0.2339\n",
      "Epoch 49/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8868 - loss: 0.3511 - val_accuracy: 0.9327 - val_loss: 0.2318\n",
      "Epoch 50/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8911 - loss: 0.3427 - val_accuracy: 0.9343 - val_loss: 0.2315\n",
      "Epoch 51/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8879 - loss: 0.3450 - val_accuracy: 0.9339 - val_loss: 0.2308\n",
      "Epoch 52/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8893 - loss: 0.3469 - val_accuracy: 0.9337 - val_loss: 0.2287\n",
      "Epoch 53/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8874 - loss: 0.3464 - val_accuracy: 0.9342 - val_loss: 0.2283\n",
      "Epoch 54/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8920 - loss: 0.3378 - val_accuracy: 0.9341 - val_loss: 0.2278\n",
      "Epoch 55/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8898 - loss: 0.3443 - val_accuracy: 0.9345 - val_loss: 0.2280\n",
      "Epoch 56/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.3383 - val_accuracy: 0.9355 - val_loss: 0.2264\n",
      "Epoch 57/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8902 - loss: 0.3462 - val_accuracy: 0.9358 - val_loss: 0.2267\n",
      "Epoch 58/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8871 - loss: 0.3495 - val_accuracy: 0.9359 - val_loss: 0.2246\n",
      "Epoch 59/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8952 - loss: 0.3351 - val_accuracy: 0.9362 - val_loss: 0.2236\n",
      "Epoch 60/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8912 - loss: 0.3352 - val_accuracy: 0.9367 - val_loss: 0.2227\n",
      "Epoch 61/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8922 - loss: 0.3338 - val_accuracy: 0.9369 - val_loss: 0.2219\n",
      "Epoch 62/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8939 - loss: 0.3316 - val_accuracy: 0.9373 - val_loss: 0.2221\n",
      "Epoch 63/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8931 - loss: 0.3295 - val_accuracy: 0.9374 - val_loss: 0.2201\n",
      "Epoch 64/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8920 - loss: 0.3324 - val_accuracy: 0.9373 - val_loss: 0.2190\n",
      "Epoch 65/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8954 - loss: 0.3272 - val_accuracy: 0.9373 - val_loss: 0.2180\n",
      "Epoch 66/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8930 - loss: 0.3264 - val_accuracy: 0.9387 - val_loss: 0.2181\n",
      "Epoch 67/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8961 - loss: 0.3263 - val_accuracy: 0.9387 - val_loss: 0.2176\n",
      "Epoch 68/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8968 - loss: 0.3226 - val_accuracy: 0.9385 - val_loss: 0.2174\n",
      "Epoch 69/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8941 - loss: 0.3263 - val_accuracy: 0.9388 - val_loss: 0.2162\n",
      "Epoch 70/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8965 - loss: 0.3233 - val_accuracy: 0.9386 - val_loss: 0.2168\n",
      "Epoch 71/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8974 - loss: 0.3170 - val_accuracy: 0.9389 - val_loss: 0.2153\n",
      "Epoch 72/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8968 - loss: 0.3207 - val_accuracy: 0.9389 - val_loss: 0.2160\n",
      "Epoch 73/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8950 - loss: 0.3258 - val_accuracy: 0.9404 - val_loss: 0.2142\n",
      "Epoch 74/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9006 - loss: 0.3107 - val_accuracy: 0.9403 - val_loss: 0.2147\n",
      "Epoch 75/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8978 - loss: 0.3157 - val_accuracy: 0.9395 - val_loss: 0.2145\n",
      "Epoch 76/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8971 - loss: 0.3203 - val_accuracy: 0.9405 - val_loss: 0.2129\n",
      "Epoch 77/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8973 - loss: 0.3197 - val_accuracy: 0.9409 - val_loss: 0.2121\n",
      "Epoch 78/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8983 - loss: 0.3121 - val_accuracy: 0.9393 - val_loss: 0.2124\n",
      "Epoch 79/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9001 - loss: 0.3096 - val_accuracy: 0.9406 - val_loss: 0.2119\n",
      "Epoch 80/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8995 - loss: 0.3155 - val_accuracy: 0.9404 - val_loss: 0.2102\n",
      "Epoch 81/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8967 - loss: 0.3164 - val_accuracy: 0.9391 - val_loss: 0.2102\n",
      "Epoch 82/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9030 - loss: 0.3018 - val_accuracy: 0.9398 - val_loss: 0.2098\n",
      "Epoch 83/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9005 - loss: 0.3018 - val_accuracy: 0.9403 - val_loss: 0.2096\n",
      "Epoch 84/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9011 - loss: 0.3057 - val_accuracy: 0.9410 - val_loss: 0.2091\n",
      "Epoch 85/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9003 - loss: 0.3031 - val_accuracy: 0.9398 - val_loss: 0.2088\n",
      "Epoch 86/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8997 - loss: 0.3103 - val_accuracy: 0.9410 - val_loss: 0.2081\n",
      "Epoch 87/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9019 - loss: 0.3058 - val_accuracy: 0.9407 - val_loss: 0.2084\n",
      "Epoch 88/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8997 - loss: 0.3064 - val_accuracy: 0.9407 - val_loss: 0.2084\n",
      "Epoch 89/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9029 - loss: 0.3046 - val_accuracy: 0.9416 - val_loss: 0.2068\n",
      "Epoch 90/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8991 - loss: 0.3101 - val_accuracy: 0.9413 - val_loss: 0.2066\n",
      "Epoch 91/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9005 - loss: 0.3080 - val_accuracy: 0.9413 - val_loss: 0.2063\n",
      "Epoch 92/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9011 - loss: 0.3065 - val_accuracy: 0.9411 - val_loss: 0.2058\n",
      "Epoch 93/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9021 - loss: 0.3008 - val_accuracy: 0.9413 - val_loss: 0.2053\n",
      "Epoch 94/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9046 - loss: 0.2993 - val_accuracy: 0.9414 - val_loss: 0.2049\n",
      "Epoch 95/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9060 - loss: 0.2905 - val_accuracy: 0.9417 - val_loss: 0.2046\n",
      "Epoch 96/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9017 - loss: 0.3002 - val_accuracy: 0.9411 - val_loss: 0.2053\n",
      "Epoch 97/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9040 - loss: 0.2997 - val_accuracy: 0.9411 - val_loss: 0.2046\n",
      "Epoch 98/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9018 - loss: 0.3014 - val_accuracy: 0.9409 - val_loss: 0.2046\n",
      "Epoch 99/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9027 - loss: 0.2981 - val_accuracy: 0.9407 - val_loss: 0.2041\n",
      "Epoch 100/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9051 - loss: 0.2947 - val_accuracy: 0.9408 - val_loss: 0.2048\n",
      "Epoch 101/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9014 - loss: 0.3032 - val_accuracy: 0.9415 - val_loss: 0.2033\n",
      "Epoch 102/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9043 - loss: 0.3012 - val_accuracy: 0.9405 - val_loss: 0.2026\n",
      "Epoch 103/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9050 - loss: 0.2924 - val_accuracy: 0.9417 - val_loss: 0.2029\n",
      "Epoch 104/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9026 - loss: 0.3020 - val_accuracy: 0.9408 - val_loss: 0.2033\n",
      "Epoch 105/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9059 - loss: 0.2935 - val_accuracy: 0.9409 - val_loss: 0.2027\n",
      "Epoch 106/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9057 - loss: 0.2889 - val_accuracy: 0.9406 - val_loss: 0.2019\n",
      "Epoch 107/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9046 - loss: 0.2924 - val_accuracy: 0.9414 - val_loss: 0.2020\n",
      "Epoch 108/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9036 - loss: 0.2924 - val_accuracy: 0.9412 - val_loss: 0.2015\n",
      "Epoch 109/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9099 - loss: 0.2832 - val_accuracy: 0.9412 - val_loss: 0.2010\n",
      "Epoch 110/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9045 - loss: 0.2952 - val_accuracy: 0.9420 - val_loss: 0.2010\n",
      "Epoch 111/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9055 - loss: 0.2930 - val_accuracy: 0.9416 - val_loss: 0.2001\n",
      "Epoch 112/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9047 - loss: 0.2947 - val_accuracy: 0.9423 - val_loss: 0.2001\n",
      "Epoch 113/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9038 - loss: 0.2930 - val_accuracy: 0.9416 - val_loss: 0.2002\n",
      "Epoch 114/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9083 - loss: 0.2838 - val_accuracy: 0.9414 - val_loss: 0.2005\n",
      "Epoch 115/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9076 - loss: 0.2842 - val_accuracy: 0.9424 - val_loss: 0.1997\n",
      "Epoch 116/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9061 - loss: 0.2833 - val_accuracy: 0.9423 - val_loss: 0.2000\n",
      "Epoch 117/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9061 - loss: 0.2883 - val_accuracy: 0.9423 - val_loss: 0.1993\n",
      "Epoch 118/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9074 - loss: 0.2867 - val_accuracy: 0.9417 - val_loss: 0.1996\n",
      "Epoch 119/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9070 - loss: 0.2873 - val_accuracy: 0.9428 - val_loss: 0.1998\n",
      "Epoch 120/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9066 - loss: 0.2899 - val_accuracy: 0.9430 - val_loss: 0.1994\n",
      "Epoch 121/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9063 - loss: 0.2900 - val_accuracy: 0.9427 - val_loss: 0.1988\n",
      "Epoch 122/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9049 - loss: 0.2899 - val_accuracy: 0.9425 - val_loss: 0.1995\n",
      "Epoch 123/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9074 - loss: 0.2847 - val_accuracy: 0.9430 - val_loss: 0.1990\n",
      "Epoch 124/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9061 - loss: 0.2872 - val_accuracy: 0.9424 - val_loss: 0.1983\n",
      "Epoch 125/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9079 - loss: 0.2826 - val_accuracy: 0.9427 - val_loss: 0.1988\n",
      "Epoch 126/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9060 - loss: 0.2860 - val_accuracy: 0.9428 - val_loss: 0.1983\n",
      "Epoch 127/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9071 - loss: 0.2869 - val_accuracy: 0.9431 - val_loss: 0.1986\n",
      "Epoch 128/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9054 - loss: 0.2876 - val_accuracy: 0.9433 - val_loss: 0.1981\n",
      "Epoch 129/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9073 - loss: 0.2824 - val_accuracy: 0.9432 - val_loss: 0.1983\n",
      "Epoch 130/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9088 - loss: 0.2777 - val_accuracy: 0.9436 - val_loss: 0.1980\n",
      "Epoch 131/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9053 - loss: 0.2901 - val_accuracy: 0.9435 - val_loss: 0.1982\n",
      "Epoch 132/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9094 - loss: 0.2776 - val_accuracy: 0.9435 - val_loss: 0.1977\n",
      "Epoch 133/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9081 - loss: 0.2774 - val_accuracy: 0.9430 - val_loss: 0.1981\n",
      "Epoch 134/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9065 - loss: 0.2855 - val_accuracy: 0.9436 - val_loss: 0.1973\n",
      "Epoch 135/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9052 - loss: 0.2863 - val_accuracy: 0.9429 - val_loss: 0.1973\n",
      "Epoch 136/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9099 - loss: 0.2799 - val_accuracy: 0.9436 - val_loss: 0.1975\n",
      "Epoch 137/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9063 - loss: 0.2813 - val_accuracy: 0.9431 - val_loss: 0.1972\n",
      "Epoch 138/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9122 - loss: 0.2761 - val_accuracy: 0.9432 - val_loss: 0.1968\n",
      "Epoch 139/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9096 - loss: 0.2775 - val_accuracy: 0.9433 - val_loss: 0.1977\n",
      "Epoch 140/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9099 - loss: 0.2740 - val_accuracy: 0.9437 - val_loss: 0.1970\n",
      "Epoch 141/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9065 - loss: 0.2827 - val_accuracy: 0.9439 - val_loss: 0.1968\n",
      "Epoch 142/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9116 - loss: 0.2735 - val_accuracy: 0.9441 - val_loss: 0.1973\n",
      "Epoch 143/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9076 - loss: 0.2806 - val_accuracy: 0.9434 - val_loss: 0.1969\n",
      "Epoch 144/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9108 - loss: 0.2785 - val_accuracy: 0.9435 - val_loss: 0.1977\n",
      "Epoch 145/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9099 - loss: 0.2724 - val_accuracy: 0.9447 - val_loss: 0.1959\n",
      "Epoch 146/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9129 - loss: 0.2697 - val_accuracy: 0.9442 - val_loss: 0.1965\n",
      "Epoch 147/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9079 - loss: 0.2793 - val_accuracy: 0.9442 - val_loss: 0.1970\n",
      "Epoch 148/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9071 - loss: 0.2834 - val_accuracy: 0.9438 - val_loss: 0.1958\n",
      "Epoch 149/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9106 - loss: 0.2775 - val_accuracy: 0.9440 - val_loss: 0.1957\n",
      "Epoch 150/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9117 - loss: 0.2689 - val_accuracy: 0.9439 - val_loss: 0.1962\n",
      "Epoch 151/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9127 - loss: 0.2735 - val_accuracy: 0.9435 - val_loss: 0.1968\n",
      "Epoch 152/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9099 - loss: 0.2719 - val_accuracy: 0.9442 - val_loss: 0.1962\n",
      "Epoch 153/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9120 - loss: 0.2715 - val_accuracy: 0.9441 - val_loss: 0.1965\n",
      "Epoch 154/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9113 - loss: 0.2758 - val_accuracy: 0.9451 - val_loss: 0.1956\n",
      "Epoch 155/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9100 - loss: 0.2776 - val_accuracy: 0.9442 - val_loss: 0.1956\n",
      "Epoch 156/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9101 - loss: 0.2693 - val_accuracy: 0.9443 - val_loss: 0.1955\n",
      "Epoch 157/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9092 - loss: 0.2757 - val_accuracy: 0.9446 - val_loss: 0.1970\n",
      "Epoch 158/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9124 - loss: 0.2691 - val_accuracy: 0.9446 - val_loss: 0.1966\n",
      "Epoch 159/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9102 - loss: 0.2697 - val_accuracy: 0.9446 - val_loss: 0.1955\n",
      "Epoch 160/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9123 - loss: 0.2680 - val_accuracy: 0.9437 - val_loss: 0.1962\n",
      "Epoch 161/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9121 - loss: 0.2714 - val_accuracy: 0.9448 - val_loss: 0.1964\n",
      "Epoch 162/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9104 - loss: 0.2720 - val_accuracy: 0.9441 - val_loss: 0.1949\n",
      "Epoch 163/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9103 - loss: 0.2743 - val_accuracy: 0.9454 - val_loss: 0.1949\n",
      "Epoch 164/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9119 - loss: 0.2685 - val_accuracy: 0.9444 - val_loss: 0.1953\n",
      "Epoch 165/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9143 - loss: 0.2625 - val_accuracy: 0.9448 - val_loss: 0.1952\n",
      "Epoch 166/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9114 - loss: 0.2704 - val_accuracy: 0.9448 - val_loss: 0.1947\n",
      "Epoch 167/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9131 - loss: 0.2663 - val_accuracy: 0.9457 - val_loss: 0.1945\n",
      "Epoch 168/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9129 - loss: 0.2662 - val_accuracy: 0.9448 - val_loss: 0.1950\n",
      "Epoch 169/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9137 - loss: 0.2657 - val_accuracy: 0.9445 - val_loss: 0.1949\n",
      "Epoch 170/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9125 - loss: 0.2717 - val_accuracy: 0.9455 - val_loss: 0.1945\n",
      "Epoch 171/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9139 - loss: 0.2636 - val_accuracy: 0.9452 - val_loss: 0.1943\n",
      "Epoch 172/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9127 - loss: 0.2667 - val_accuracy: 0.9452 - val_loss: 0.1954\n",
      "Epoch 173/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9110 - loss: 0.2709 - val_accuracy: 0.9448 - val_loss: 0.1956\n",
      "Epoch 174/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9120 - loss: 0.2651 - val_accuracy: 0.9452 - val_loss: 0.1952\n",
      "Epoch 175/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9108 - loss: 0.2664 - val_accuracy: 0.9441 - val_loss: 0.1957\n",
      "Epoch 176/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9084 - loss: 0.2715 - val_accuracy: 0.9453 - val_loss: 0.1946\n",
      "Epoch 177/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9120 - loss: 0.2685 - val_accuracy: 0.9448 - val_loss: 0.1962\n",
      "Epoch 178/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9121 - loss: 0.2657 - val_accuracy: 0.9457 - val_loss: 0.1942\n",
      "Epoch 179/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9125 - loss: 0.2613 - val_accuracy: 0.9449 - val_loss: 0.1941\n",
      "Epoch 180/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9134 - loss: 0.2719 - val_accuracy: 0.9454 - val_loss: 0.1936\n",
      "Epoch 181/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9133 - loss: 0.2635 - val_accuracy: 0.9454 - val_loss: 0.1944\n",
      "Epoch 182/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9133 - loss: 0.2642 - val_accuracy: 0.9457 - val_loss: 0.1949\n",
      "Epoch 183/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.2640 - val_accuracy: 0.9455 - val_loss: 0.1957\n",
      "Epoch 184/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9140 - loss: 0.2686 - val_accuracy: 0.9449 - val_loss: 0.1946\n",
      "Epoch 185/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9101 - loss: 0.2731 - val_accuracy: 0.9448 - val_loss: 0.1954\n",
      "Epoch 186/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9115 - loss: 0.2654 - val_accuracy: 0.9444 - val_loss: 0.1954\n",
      "Epoch 187/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9155 - loss: 0.2567 - val_accuracy: 0.9448 - val_loss: 0.1953\n",
      "Epoch 188/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9148 - loss: 0.2620 - val_accuracy: 0.9453 - val_loss: 0.1953\n",
      "Epoch 189/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9126 - loss: 0.2657 - val_accuracy: 0.9451 - val_loss: 0.1953\n",
      "Epoch 190/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9142 - loss: 0.2673 - val_accuracy: 0.9451 - val_loss: 0.1964\n",
      "Epoch 191/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9135 - loss: 0.2590 - val_accuracy: 0.9457 - val_loss: 0.1955\n",
      "Epoch 192/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9139 - loss: 0.2657 - val_accuracy: 0.9464 - val_loss: 0.1950\n",
      "Epoch 193/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9156 - loss: 0.2562 - val_accuracy: 0.9448 - val_loss: 0.1951\n",
      "Epoch 194/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.2642 - val_accuracy: 0.9450 - val_loss: 0.1949\n",
      "Epoch 195/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9132 - loss: 0.2630 - val_accuracy: 0.9455 - val_loss: 0.1954\n",
      "Epoch 196/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9117 - loss: 0.2688 - val_accuracy: 0.9450 - val_loss: 0.1965\n",
      "Epoch 197/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9157 - loss: 0.2606 - val_accuracy: 0.9447 - val_loss: 0.1952\n",
      "Epoch 198/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9150 - loss: 0.2567 - val_accuracy: 0.9450 - val_loss: 0.1959\n",
      "Epoch 199/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.2546 - val_accuracy: 0.9450 - val_loss: 0.1954\n",
      "Epoch 200/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9143 - loss: 0.2675 - val_accuracy: 0.9454 - val_loss: 0.1953\n",
      "Epoch 201/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9153 - loss: 0.2621 - val_accuracy: 0.9448 - val_loss: 0.1964\n",
      "Epoch 202/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9162 - loss: 0.2527 - val_accuracy: 0.9451 - val_loss: 0.1962\n",
      "Epoch 203/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9143 - loss: 0.2629 - val_accuracy: 0.9448 - val_loss: 0.1966\n",
      "Epoch 204/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9156 - loss: 0.2568 - val_accuracy: 0.9452 - val_loss: 0.1956\n",
      "Epoch 205/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9161 - loss: 0.2584 - val_accuracy: 0.9442 - val_loss: 0.1964\n",
      "Epoch 206/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9144 - loss: 0.2595 - val_accuracy: 0.9459 - val_loss: 0.1963\n",
      "Epoch 207/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9146 - loss: 0.2610 - val_accuracy: 0.9453 - val_loss: 0.1965\n",
      "Epoch 208/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9129 - loss: 0.2631 - val_accuracy: 0.9453 - val_loss: 0.1962\n",
      "Epoch 209/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9169 - loss: 0.2568 - val_accuracy: 0.9455 - val_loss: 0.1961\n",
      "Epoch 210/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9183 - loss: 0.2505 - val_accuracy: 0.9453 - val_loss: 0.1957\n",
      "Epoch 211/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9123 - loss: 0.2681 - val_accuracy: 0.9450 - val_loss: 0.1963\n",
      "Epoch 212/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9155 - loss: 0.2554 - val_accuracy: 0.9456 - val_loss: 0.1962\n",
      "Epoch 213/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9148 - loss: 0.2550 - val_accuracy: 0.9446 - val_loss: 0.1963\n",
      "Epoch 214/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9160 - loss: 0.2554 - val_accuracy: 0.9458 - val_loss: 0.1967\n",
      "Epoch 215/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9152 - loss: 0.2575 - val_accuracy: 0.9450 - val_loss: 0.1964\n",
      "Epoch 216/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9153 - loss: 0.2596 - val_accuracy: 0.9451 - val_loss: 0.1966\n",
      "Epoch 217/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9172 - loss: 0.2539 - val_accuracy: 0.9447 - val_loss: 0.1963\n",
      "Epoch 218/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9162 - loss: 0.2575 - val_accuracy: 0.9448 - val_loss: 0.1970\n",
      "Epoch 219/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9177 - loss: 0.2525 - val_accuracy: 0.9451 - val_loss: 0.1959\n",
      "Epoch 220/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9157 - loss: 0.2581 - val_accuracy: 0.9448 - val_loss: 0.1978\n",
      "Epoch 221/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9153 - loss: 0.2593 - val_accuracy: 0.9448 - val_loss: 0.1964\n",
      "Epoch 222/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9161 - loss: 0.2561 - val_accuracy: 0.9460 - val_loss: 0.1962\n",
      "Epoch 223/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9167 - loss: 0.2581 - val_accuracy: 0.9455 - val_loss: 0.1956\n",
      "Epoch 224/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9180 - loss: 0.2492 - val_accuracy: 0.9450 - val_loss: 0.1966\n",
      "Epoch 225/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9153 - loss: 0.2575 - val_accuracy: 0.9450 - val_loss: 0.1967\n",
      "Epoch 226/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9189 - loss: 0.2558 - val_accuracy: 0.9448 - val_loss: 0.1978\n",
      "Epoch 227/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9175 - loss: 0.2526 - val_accuracy: 0.9446 - val_loss: 0.1972\n",
      "Epoch 228/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9160 - loss: 0.2525 - val_accuracy: 0.9453 - val_loss: 0.1966\n",
      "Epoch 229/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9138 - loss: 0.2627 - val_accuracy: 0.9460 - val_loss: 0.1959\n",
      "Epoch 230/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9149 - loss: 0.2586 - val_accuracy: 0.9454 - val_loss: 0.1980\n",
      "Epoch 231/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9155 - loss: 0.2601 - val_accuracy: 0.9461 - val_loss: 0.1966\n",
      "Epoch 232/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9131 - loss: 0.2601 - val_accuracy: 0.9454 - val_loss: 0.1966\n",
      "Epoch 233/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9147 - loss: 0.2545 - val_accuracy: 0.9455 - val_loss: 0.1962\n",
      "Epoch 234/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9151 - loss: 0.2577 - val_accuracy: 0.9458 - val_loss: 0.1966\n",
      "Epoch 235/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9162 - loss: 0.2536 - val_accuracy: 0.9455 - val_loss: 0.1968\n",
      "Epoch 236/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9185 - loss: 0.2470 - val_accuracy: 0.9452 - val_loss: 0.1981\n",
      "Epoch 237/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9192 - loss: 0.2486 - val_accuracy: 0.9462 - val_loss: 0.1972\n",
      "Epoch 238/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9152 - loss: 0.2583 - val_accuracy: 0.9453 - val_loss: 0.1984\n",
      "Epoch 239/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9165 - loss: 0.2544 - val_accuracy: 0.9455 - val_loss: 0.1969\n",
      "Epoch 240/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9160 - loss: 0.2555 - val_accuracy: 0.9462 - val_loss: 0.1973\n",
      "Epoch 241/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9166 - loss: 0.2531 - val_accuracy: 0.9456 - val_loss: 0.1977\n",
      "Epoch 242/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9159 - loss: 0.2573 - val_accuracy: 0.9448 - val_loss: 0.1973\n",
      "Epoch 243/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.2470 - val_accuracy: 0.9455 - val_loss: 0.1977\n",
      "Epoch 244/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9165 - loss: 0.2588 - val_accuracy: 0.9457 - val_loss: 0.1978\n",
      "Epoch 245/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9157 - loss: 0.2617 - val_accuracy: 0.9455 - val_loss: 0.1982\n",
      "Epoch 246/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9180 - loss: 0.2497 - val_accuracy: 0.9460 - val_loss: 0.1965\n",
      "Epoch 247/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9157 - loss: 0.2548 - val_accuracy: 0.9453 - val_loss: 0.1978\n",
      "Epoch 248/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9182 - loss: 0.2566 - val_accuracy: 0.9467 - val_loss: 0.1965\n",
      "Epoch 249/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9163 - loss: 0.2561 - val_accuracy: 0.9457 - val_loss: 0.1982\n",
      "Epoch 250/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9169 - loss: 0.2495 - val_accuracy: 0.9448 - val_loss: 0.1983\n",
      "Epoch 251/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.2528 - val_accuracy: 0.9452 - val_loss: 0.1984\n",
      "Epoch 252/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9183 - loss: 0.2555 - val_accuracy: 0.9448 - val_loss: 0.1989\n",
      "Epoch 253/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9152 - loss: 0.2550 - val_accuracy: 0.9457 - val_loss: 0.1981\n",
      "Epoch 254/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9186 - loss: 0.2502 - val_accuracy: 0.9455 - val_loss: 0.1986\n",
      "Epoch 255/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9189 - loss: 0.2495 - val_accuracy: 0.9449 - val_loss: 0.1980\n",
      "Epoch 256/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9168 - loss: 0.2531 - val_accuracy: 0.9447 - val_loss: 0.1981\n",
      "Epoch 257/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9179 - loss: 0.2495 - val_accuracy: 0.9448 - val_loss: 0.1995\n",
      "Epoch 258/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9191 - loss: 0.2489 - val_accuracy: 0.9454 - val_loss: 0.1997\n",
      "Epoch 259/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9184 - loss: 0.2477 - val_accuracy: 0.9464 - val_loss: 0.1991\n",
      "Epoch 260/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9174 - loss: 0.2526 - val_accuracy: 0.9463 - val_loss: 0.1985\n",
      "Epoch 261/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9185 - loss: 0.2486 - val_accuracy: 0.9456 - val_loss: 0.1985\n",
      "Epoch 262/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9171 - loss: 0.2480 - val_accuracy: 0.9456 - val_loss: 0.1981\n",
      "Epoch 263/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9172 - loss: 0.2511 - val_accuracy: 0.9449 - val_loss: 0.1988\n",
      "Epoch 264/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9181 - loss: 0.2522 - val_accuracy: 0.9443 - val_loss: 0.1997\n",
      "Epoch 265/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.2502 - val_accuracy: 0.9454 - val_loss: 0.1996\n",
      "Epoch 266/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9180 - loss: 0.2480 - val_accuracy: 0.9457 - val_loss: 0.1990\n",
      "Epoch 267/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9196 - loss: 0.2486 - val_accuracy: 0.9462 - val_loss: 0.1994\n",
      "Epoch 268/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9200 - loss: 0.2457 - val_accuracy: 0.9457 - val_loss: 0.1999\n",
      "Epoch 269/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9174 - loss: 0.2478 - val_accuracy: 0.9455 - val_loss: 0.1988\n",
      "Epoch 270/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9174 - loss: 0.2466 - val_accuracy: 0.9452 - val_loss: 0.1986\n",
      "Epoch 271/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9180 - loss: 0.2469 - val_accuracy: 0.9449 - val_loss: 0.1988\n",
      "Epoch 272/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9203 - loss: 0.2454 - val_accuracy: 0.9447 - val_loss: 0.1989\n",
      "Epoch 273/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9180 - loss: 0.2512 - val_accuracy: 0.9447 - val_loss: 0.1998\n",
      "Epoch 274/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9199 - loss: 0.2466 - val_accuracy: 0.9449 - val_loss: 0.1997\n",
      "Epoch 275/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9193 - loss: 0.2441 - val_accuracy: 0.9455 - val_loss: 0.1995\n",
      "Epoch 276/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9215 - loss: 0.2394 - val_accuracy: 0.9459 - val_loss: 0.1996\n",
      "Epoch 277/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9220 - loss: 0.2471 - val_accuracy: 0.9448 - val_loss: 0.2010\n",
      "Epoch 278/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.2507 - val_accuracy: 0.9448 - val_loss: 0.2018\n",
      "Epoch 279/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9218 - loss: 0.2416 - val_accuracy: 0.9456 - val_loss: 0.1998\n",
      "Epoch 280/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9187 - loss: 0.2459 - val_accuracy: 0.9447 - val_loss: 0.2015\n",
      "Epoch 281/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9208 - loss: 0.2453 - val_accuracy: 0.9447 - val_loss: 0.2015\n",
      "Epoch 282/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9194 - loss: 0.2498 - val_accuracy: 0.9457 - val_loss: 0.2001\n",
      "Epoch 283/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9183 - loss: 0.2476 - val_accuracy: 0.9448 - val_loss: 0.2015\n",
      "Epoch 284/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9224 - loss: 0.2433 - val_accuracy: 0.9438 - val_loss: 0.2017\n",
      "Epoch 285/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9191 - loss: 0.2468 - val_accuracy: 0.9453 - val_loss: 0.2021\n",
      "Epoch 286/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9194 - loss: 0.2474 - val_accuracy: 0.9440 - val_loss: 0.2014\n",
      "Epoch 287/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9201 - loss: 0.2432 - val_accuracy: 0.9447 - val_loss: 0.2008\n",
      "Epoch 288/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9183 - loss: 0.2457 - val_accuracy: 0.9452 - val_loss: 0.2018\n",
      "Epoch 289/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9210 - loss: 0.2429 - val_accuracy: 0.9458 - val_loss: 0.1999\n",
      "Epoch 290/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9192 - loss: 0.2445 - val_accuracy: 0.9448 - val_loss: 0.2020\n",
      "Epoch 291/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9187 - loss: 0.2473 - val_accuracy: 0.9455 - val_loss: 0.2013\n",
      "Epoch 292/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9167 - loss: 0.2505 - val_accuracy: 0.9446 - val_loss: 0.2029\n",
      "Epoch 293/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9216 - loss: 0.2403 - val_accuracy: 0.9452 - val_loss: 0.2026\n",
      "Epoch 294/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9208 - loss: 0.2407 - val_accuracy: 0.9451 - val_loss: 0.2026\n",
      "Epoch 295/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9206 - loss: 0.2416 - val_accuracy: 0.9451 - val_loss: 0.2015\n",
      "Epoch 296/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9174 - loss: 0.2438 - val_accuracy: 0.9450 - val_loss: 0.2012\n",
      "Epoch 297/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9187 - loss: 0.2498 - val_accuracy: 0.9450 - val_loss: 0.2019\n",
      "Epoch 298/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9194 - loss: 0.2441 - val_accuracy: 0.9452 - val_loss: 0.2021\n",
      "Epoch 299/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9210 - loss: 0.2418 - val_accuracy: 0.9450 - val_loss: 0.2018\n",
      "Epoch 300/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9184 - loss: 0.2476 - val_accuracy: 0.9442 - val_loss: 0.2029\n",
      "Epoch 301/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9218 - loss: 0.2410 - val_accuracy: 0.9453 - val_loss: 0.2016\n",
      "Epoch 302/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9196 - loss: 0.2397 - val_accuracy: 0.9453 - val_loss: 0.2016\n",
      "Epoch 303/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9194 - loss: 0.2423 - val_accuracy: 0.9448 - val_loss: 0.2023\n",
      "Epoch 304/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9193 - loss: 0.2440 - val_accuracy: 0.9451 - val_loss: 0.2028\n",
      "Epoch 305/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9180 - loss: 0.2457 - val_accuracy: 0.9462 - val_loss: 0.2019\n",
      "Epoch 306/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9226 - loss: 0.2432 - val_accuracy: 0.9450 - val_loss: 0.2017\n",
      "Epoch 307/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9189 - loss: 0.2425 - val_accuracy: 0.9448 - val_loss: 0.2020\n",
      "Epoch 308/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9195 - loss: 0.2461 - val_accuracy: 0.9450 - val_loss: 0.2026\n",
      "Epoch 309/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9209 - loss: 0.2383 - val_accuracy: 0.9448 - val_loss: 0.2027\n",
      "Epoch 310/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9188 - loss: 0.2399 - val_accuracy: 0.9445 - val_loss: 0.2037\n",
      "Epoch 311/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9206 - loss: 0.2407 - val_accuracy: 0.9450 - val_loss: 0.2033\n",
      "Epoch 312/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9181 - loss: 0.2464 - val_accuracy: 0.9453 - val_loss: 0.2023\n",
      "Epoch 313/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9238 - loss: 0.2360 - val_accuracy: 0.9458 - val_loss: 0.2018\n",
      "Epoch 314/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9174 - loss: 0.2484 - val_accuracy: 0.9444 - val_loss: 0.2031\n",
      "Epoch 315/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9194 - loss: 0.2453 - val_accuracy: 0.9448 - val_loss: 0.2038\n",
      "Epoch 316/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9212 - loss: 0.2444 - val_accuracy: 0.9449 - val_loss: 0.2038\n",
      "Epoch 317/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9201 - loss: 0.2409 - val_accuracy: 0.9443 - val_loss: 0.2050\n",
      "Epoch 318/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9184 - loss: 0.2449 - val_accuracy: 0.9448 - val_loss: 0.2042\n",
      "Epoch 319/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9207 - loss: 0.2404 - val_accuracy: 0.9442 - val_loss: 0.2036\n",
      "Epoch 320/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9195 - loss: 0.2451 - val_accuracy: 0.9449 - val_loss: 0.2045\n",
      "Epoch 321/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9221 - loss: 0.2410 - val_accuracy: 0.9445 - val_loss: 0.2056\n",
      "Epoch 322/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9206 - loss: 0.2411 - val_accuracy: 0.9449 - val_loss: 0.2035\n",
      "Epoch 323/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9214 - loss: 0.2420 - val_accuracy: 0.9450 - val_loss: 0.2031\n",
      "Epoch 324/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9172 - loss: 0.2541 - val_accuracy: 0.9447 - val_loss: 0.2048\n",
      "Epoch 325/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9232 - loss: 0.2380 - val_accuracy: 0.9449 - val_loss: 0.2050\n",
      "Epoch 326/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9194 - loss: 0.2416 - val_accuracy: 0.9450 - val_loss: 0.2045\n",
      "Epoch 327/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9209 - loss: 0.2485 - val_accuracy: 0.9449 - val_loss: 0.2050\n",
      "Epoch 328/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9177 - loss: 0.2471 - val_accuracy: 0.9451 - val_loss: 0.2051\n",
      "Epoch 329/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9196 - loss: 0.2461 - val_accuracy: 0.9456 - val_loss: 0.2047\n",
      "Epoch 330/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9199 - loss: 0.2443 - val_accuracy: 0.9450 - val_loss: 0.2057\n",
      "Epoch 331/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9189 - loss: 0.2472 - val_accuracy: 0.9452 - val_loss: 0.2060\n",
      "Epoch 332/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9197 - loss: 0.2482 - val_accuracy: 0.9452 - val_loss: 0.2054\n",
      "Epoch 333/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9201 - loss: 0.2384 - val_accuracy: 0.9449 - val_loss: 0.2055\n",
      "Epoch 334/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9198 - loss: 0.2424 - val_accuracy: 0.9453 - val_loss: 0.2050\n",
      "Epoch 335/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9174 - loss: 0.2455 - val_accuracy: 0.9449 - val_loss: 0.2046\n",
      "Epoch 336/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9225 - loss: 0.2391 - val_accuracy: 0.9451 - val_loss: 0.2044\n",
      "Epoch 337/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9144 - loss: 0.2548 - val_accuracy: 0.9452 - val_loss: 0.2062\n",
      "Epoch 338/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9219 - loss: 0.2362 - val_accuracy: 0.9448 - val_loss: 0.2054\n",
      "Epoch 339/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9195 - loss: 0.2432 - val_accuracy: 0.9447 - val_loss: 0.2058\n",
      "Epoch 340/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9229 - loss: 0.2386 - val_accuracy: 0.9454 - val_loss: 0.2076\n",
      "Epoch 341/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9209 - loss: 0.2395 - val_accuracy: 0.9449 - val_loss: 0.2068\n",
      "Epoch 342/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9225 - loss: 0.2399 - val_accuracy: 0.9442 - val_loss: 0.2066\n",
      "Epoch 343/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9189 - loss: 0.2460 - val_accuracy: 0.9446 - val_loss: 0.2066\n",
      "Epoch 344/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9180 - loss: 0.2522 - val_accuracy: 0.9443 - val_loss: 0.2062\n",
      "Epoch 345/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9197 - loss: 0.2458 - val_accuracy: 0.9442 - val_loss: 0.2072\n",
      "Epoch 346/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9190 - loss: 0.2459 - val_accuracy: 0.9447 - val_loss: 0.2065\n",
      "Epoch 347/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9206 - loss: 0.2442 - val_accuracy: 0.9448 - val_loss: 0.2055\n",
      "Epoch 348/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9204 - loss: 0.2418 - val_accuracy: 0.9450 - val_loss: 0.2070\n",
      "Epoch 349/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9224 - loss: 0.2398 - val_accuracy: 0.9451 - val_loss: 0.2066\n",
      "Epoch 350/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9216 - loss: 0.2380 - val_accuracy: 0.9450 - val_loss: 0.2068\n",
      "Epoch 351/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9243 - loss: 0.2342 - val_accuracy: 0.9441 - val_loss: 0.2075\n",
      "Epoch 352/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9221 - loss: 0.2375 - val_accuracy: 0.9445 - val_loss: 0.2077\n",
      "Epoch 353/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9220 - loss: 0.2358 - val_accuracy: 0.9449 - val_loss: 0.2072\n",
      "Epoch 354/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9224 - loss: 0.2374 - val_accuracy: 0.9446 - val_loss: 0.2071\n",
      "Epoch 355/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9208 - loss: 0.2415 - val_accuracy: 0.9446 - val_loss: 0.2076\n",
      "Epoch 356/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9238 - loss: 0.2323 - val_accuracy: 0.9449 - val_loss: 0.2058\n",
      "Epoch 357/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9190 - loss: 0.2462 - val_accuracy: 0.9448 - val_loss: 0.2083\n",
      "Epoch 358/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9191 - loss: 0.2385 - val_accuracy: 0.9448 - val_loss: 0.2066\n",
      "Epoch 359/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9215 - loss: 0.2361 - val_accuracy: 0.9450 - val_loss: 0.2077\n",
      "Epoch 360/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9199 - loss: 0.2419 - val_accuracy: 0.9448 - val_loss: 0.2078\n",
      "Epoch 361/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9229 - loss: 0.2369 - val_accuracy: 0.9453 - val_loss: 0.2075\n",
      "Epoch 362/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9208 - loss: 0.2413 - val_accuracy: 0.9447 - val_loss: 0.2074\n",
      "Epoch 363/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9211 - loss: 0.2359 - val_accuracy: 0.9449 - val_loss: 0.2083\n",
      "Epoch 364/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9213 - loss: 0.2378 - val_accuracy: 0.9446 - val_loss: 0.2078\n",
      "Epoch 365/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9202 - loss: 0.2399 - val_accuracy: 0.9447 - val_loss: 0.2083\n",
      "Epoch 366/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9211 - loss: 0.2374 - val_accuracy: 0.9449 - val_loss: 0.2083\n",
      "Epoch 367/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9244 - loss: 0.2340 - val_accuracy: 0.9448 - val_loss: 0.2087\n",
      "Epoch 368/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9197 - loss: 0.2392 - val_accuracy: 0.9449 - val_loss: 0.2103\n",
      "Epoch 369/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9213 - loss: 0.2409 - val_accuracy: 0.9445 - val_loss: 0.2080\n",
      "Epoch 370/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9211 - loss: 0.2399 - val_accuracy: 0.9452 - val_loss: 0.2085\n",
      "Epoch 371/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9205 - loss: 0.2422 - val_accuracy: 0.9439 - val_loss: 0.2108\n",
      "Epoch 372/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9228 - loss: 0.2329 - val_accuracy: 0.9431 - val_loss: 0.2096\n",
      "Epoch 373/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9212 - loss: 0.2425 - val_accuracy: 0.9446 - val_loss: 0.2096\n",
      "Epoch 374/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9199 - loss: 0.2369 - val_accuracy: 0.9440 - val_loss: 0.2104\n",
      "Epoch 375/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9208 - loss: 0.2353 - val_accuracy: 0.9440 - val_loss: 0.2097\n",
      "Epoch 376/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9207 - loss: 0.2432 - val_accuracy: 0.9438 - val_loss: 0.2113\n",
      "Epoch 377/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9214 - loss: 0.2418 - val_accuracy: 0.9440 - val_loss: 0.2105\n",
      "Epoch 378/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9209 - loss: 0.2414 - val_accuracy: 0.9443 - val_loss: 0.2088\n",
      "Epoch 379/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9212 - loss: 0.2387 - val_accuracy: 0.9442 - val_loss: 0.2105\n",
      "Epoch 380/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9222 - loss: 0.2363 - val_accuracy: 0.9444 - val_loss: 0.2110\n",
      "Epoch 381/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9231 - loss: 0.2375 - val_accuracy: 0.9449 - val_loss: 0.2103\n",
      "Epoch 382/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9238 - loss: 0.2305 - val_accuracy: 0.9438 - val_loss: 0.2123\n",
      "Epoch 383/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9206 - loss: 0.2400 - val_accuracy: 0.9446 - val_loss: 0.2099\n",
      "Epoch 384/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.2361 - val_accuracy: 0.9449 - val_loss: 0.2110\n",
      "Epoch 385/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9229 - loss: 0.2330 - val_accuracy: 0.9445 - val_loss: 0.2112\n",
      "Epoch 386/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9217 - loss: 0.2414 - val_accuracy: 0.9452 - val_loss: 0.2106\n",
      "Epoch 387/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 0.2379 - val_accuracy: 0.9435 - val_loss: 0.2137\n",
      "Epoch 388/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9229 - loss: 0.2378 - val_accuracy: 0.9453 - val_loss: 0.2115\n",
      "Epoch 389/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.2325 - val_accuracy: 0.9445 - val_loss: 0.2109\n",
      "Epoch 390/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 0.2384 - val_accuracy: 0.9443 - val_loss: 0.2122\n",
      "Epoch 391/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9210 - loss: 0.2362 - val_accuracy: 0.9450 - val_loss: 0.2118\n",
      "Epoch 392/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9211 - loss: 0.2392 - val_accuracy: 0.9448 - val_loss: 0.2130\n",
      "Epoch 393/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9216 - loss: 0.2345 - val_accuracy: 0.9448 - val_loss: 0.2120\n",
      "Epoch 394/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9202 - loss: 0.2381 - val_accuracy: 0.9452 - val_loss: 0.2125\n",
      "Epoch 395/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.2347 - val_accuracy: 0.9455 - val_loss: 0.2131\n",
      "Epoch 396/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9241 - loss: 0.2341 - val_accuracy: 0.9442 - val_loss: 0.2129\n",
      "Epoch 397/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9238 - loss: 0.2270 - val_accuracy: 0.9448 - val_loss: 0.2126\n",
      "Epoch 398/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9226 - loss: 0.2349 - val_accuracy: 0.9443 - val_loss: 0.2128\n",
      "Epoch 399/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 0.2370 - val_accuracy: 0.9445 - val_loss: 0.2133\n",
      "Epoch 400/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9215 - loss: 0.2358 - val_accuracy: 0.9451 - val_loss: 0.2128\n",
      "Epoch 401/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9226 - loss: 0.2345 - val_accuracy: 0.9438 - val_loss: 0.2138\n",
      "Epoch 402/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9238 - loss: 0.2362 - val_accuracy: 0.9452 - val_loss: 0.2124\n",
      "Epoch 403/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9227 - loss: 0.2374 - val_accuracy: 0.9438 - val_loss: 0.2128\n",
      "Epoch 404/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9234 - loss: 0.2325 - val_accuracy: 0.9447 - val_loss: 0.2125\n",
      "Epoch 405/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9204 - loss: 0.2404 - val_accuracy: 0.9447 - val_loss: 0.2126\n",
      "Epoch 406/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9217 - loss: 0.2353 - val_accuracy: 0.9442 - val_loss: 0.2141\n",
      "Epoch 407/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9245 - loss: 0.2279 - val_accuracy: 0.9447 - val_loss: 0.2140\n",
      "Epoch 408/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9226 - loss: 0.2335 - val_accuracy: 0.9443 - val_loss: 0.2125\n",
      "Epoch 409/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9244 - loss: 0.2293 - val_accuracy: 0.9436 - val_loss: 0.2138\n",
      "Epoch 410/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9219 - loss: 0.2376 - val_accuracy: 0.9451 - val_loss: 0.2129\n",
      "Epoch 411/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9251 - loss: 0.2308 - val_accuracy: 0.9443 - val_loss: 0.2138\n",
      "Epoch 412/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9242 - loss: 0.2324 - val_accuracy: 0.9438 - val_loss: 0.2133\n",
      "Epoch 413/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9209 - loss: 0.2376 - val_accuracy: 0.9447 - val_loss: 0.2129\n",
      "Epoch 414/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9205 - loss: 0.2398 - val_accuracy: 0.9442 - val_loss: 0.2161\n",
      "Epoch 415/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9236 - loss: 0.2313 - val_accuracy: 0.9448 - val_loss: 0.2140\n",
      "Epoch 416/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9265 - loss: 0.2253 - val_accuracy: 0.9447 - val_loss: 0.2137\n",
      "Epoch 417/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9222 - loss: 0.2350 - val_accuracy: 0.9446 - val_loss: 0.2137\n",
      "Epoch 418/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9237 - loss: 0.2342 - val_accuracy: 0.9441 - val_loss: 0.2164\n",
      "Epoch 419/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9216 - loss: 0.2394 - val_accuracy: 0.9442 - val_loss: 0.2157\n",
      "Epoch 420/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9231 - loss: 0.2316 - val_accuracy: 0.9443 - val_loss: 0.2151\n",
      "Epoch 421/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 0.2396 - val_accuracy: 0.9447 - val_loss: 0.2153\n",
      "Epoch 422/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9221 - loss: 0.2332 - val_accuracy: 0.9450 - val_loss: 0.2146\n",
      "Epoch 423/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9229 - loss: 0.2330 - val_accuracy: 0.9439 - val_loss: 0.2139\n",
      "Epoch 424/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9235 - loss: 0.2305 - val_accuracy: 0.9448 - val_loss: 0.2145\n",
      "Epoch 425/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9227 - loss: 0.2331 - val_accuracy: 0.9440 - val_loss: 0.2144\n",
      "Epoch 426/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9242 - loss: 0.2378 - val_accuracy: 0.9452 - val_loss: 0.2151\n",
      "Epoch 427/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9229 - loss: 0.2351 - val_accuracy: 0.9448 - val_loss: 0.2159\n",
      "Epoch 428/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9231 - loss: 0.2311 - val_accuracy: 0.9447 - val_loss: 0.2150\n",
      "Epoch 429/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9232 - loss: 0.2333 - val_accuracy: 0.9448 - val_loss: 0.2166\n",
      "Epoch 430/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9243 - loss: 0.2349 - val_accuracy: 0.9440 - val_loss: 0.2179\n",
      "Epoch 431/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9236 - loss: 0.2347 - val_accuracy: 0.9441 - val_loss: 0.2155\n",
      "Epoch 432/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9243 - loss: 0.2305 - val_accuracy: 0.9447 - val_loss: 0.2145\n",
      "Epoch 433/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9198 - loss: 0.2396 - val_accuracy: 0.9447 - val_loss: 0.2164\n",
      "Epoch 434/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9243 - loss: 0.2312 - val_accuracy: 0.9448 - val_loss: 0.2182\n",
      "Epoch 435/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9203 - loss: 0.2356 - val_accuracy: 0.9448 - val_loss: 0.2179\n",
      "Epoch 436/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9233 - loss: 0.2321 - val_accuracy: 0.9445 - val_loss: 0.2182\n",
      "Epoch 437/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9239 - loss: 0.2377 - val_accuracy: 0.9449 - val_loss: 0.2158\n",
      "Epoch 438/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9233 - loss: 0.2298 - val_accuracy: 0.9449 - val_loss: 0.2152\n",
      "Epoch 439/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9220 - loss: 0.2325 - val_accuracy: 0.9448 - val_loss: 0.2175\n",
      "Epoch 440/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9264 - loss: 0.2270 - val_accuracy: 0.9442 - val_loss: 0.2170\n",
      "Epoch 441/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9230 - loss: 0.2348 - val_accuracy: 0.9450 - val_loss: 0.2168\n",
      "Epoch 442/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9240 - loss: 0.2329 - val_accuracy: 0.9439 - val_loss: 0.2175\n",
      "Epoch 443/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9246 - loss: 0.2323 - val_accuracy: 0.9446 - val_loss: 0.2169\n",
      "Epoch 444/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9230 - loss: 0.2342 - val_accuracy: 0.9440 - val_loss: 0.2180\n",
      "Epoch 445/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9250 - loss: 0.2285 - val_accuracy: 0.9437 - val_loss: 0.2188\n",
      "Epoch 446/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9224 - loss: 0.2366 - val_accuracy: 0.9442 - val_loss: 0.2181\n",
      "Epoch 447/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9231 - loss: 0.2313 - val_accuracy: 0.9438 - val_loss: 0.2185\n",
      "Epoch 448/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9239 - loss: 0.2367 - val_accuracy: 0.9431 - val_loss: 0.2189\n",
      "Epoch 449/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9230 - loss: 0.2332 - val_accuracy: 0.9442 - val_loss: 0.2191\n",
      "Epoch 450/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9264 - loss: 0.2315 - val_accuracy: 0.9438 - val_loss: 0.2203\n",
      "Epoch 451/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9259 - loss: 0.2332 - val_accuracy: 0.9436 - val_loss: 0.2184\n",
      "Epoch 452/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9252 - loss: 0.2296 - val_accuracy: 0.9437 - val_loss: 0.2183\n",
      "Epoch 453/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 0.2338 - val_accuracy: 0.9440 - val_loss: 0.2194\n",
      "Epoch 454/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9235 - loss: 0.2361 - val_accuracy: 0.9444 - val_loss: 0.2179\n",
      "Epoch 455/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9216 - loss: 0.2329 - val_accuracy: 0.9446 - val_loss: 0.2168\n",
      "Epoch 456/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9207 - loss: 0.2337 - val_accuracy: 0.9429 - val_loss: 0.2190\n",
      "Epoch 457/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.2300 - val_accuracy: 0.9438 - val_loss: 0.2190\n",
      "Epoch 458/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9253 - loss: 0.2265 - val_accuracy: 0.9434 - val_loss: 0.2174\n",
      "Epoch 459/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9213 - loss: 0.2383 - val_accuracy: 0.9438 - val_loss: 0.2196\n",
      "Epoch 460/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9243 - loss: 0.2275 - val_accuracy: 0.9433 - val_loss: 0.2188\n",
      "Epoch 461/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9259 - loss: 0.2259 - val_accuracy: 0.9434 - val_loss: 0.2184\n",
      "Epoch 462/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9249 - loss: 0.2287 - val_accuracy: 0.9442 - val_loss: 0.2177\n",
      "Epoch 463/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.2312 - val_accuracy: 0.9431 - val_loss: 0.2200\n",
      "Epoch 464/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9236 - loss: 0.2314 - val_accuracy: 0.9438 - val_loss: 0.2205\n",
      "Epoch 465/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9261 - loss: 0.2250 - val_accuracy: 0.9442 - val_loss: 0.2178\n",
      "Epoch 466/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9237 - loss: 0.2323 - val_accuracy: 0.9441 - val_loss: 0.2191\n",
      "Epoch 467/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9244 - loss: 0.2332 - val_accuracy: 0.9431 - val_loss: 0.2200\n",
      "Epoch 468/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9238 - loss: 0.2296 - val_accuracy: 0.9445 - val_loss: 0.2203\n",
      "Epoch 469/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9236 - loss: 0.2317 - val_accuracy: 0.9441 - val_loss: 0.2199\n",
      "Epoch 470/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9248 - loss: 0.2314 - val_accuracy: 0.9444 - val_loss: 0.2198\n",
      "Epoch 471/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9262 - loss: 0.2275 - val_accuracy: 0.9437 - val_loss: 0.2197\n",
      "Epoch 472/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9250 - loss: 0.2253 - val_accuracy: 0.9438 - val_loss: 0.2198\n",
      "Epoch 473/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9234 - loss: 0.2321 - val_accuracy: 0.9436 - val_loss: 0.2194\n",
      "Epoch 474/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9247 - loss: 0.2291 - val_accuracy: 0.9432 - val_loss: 0.2221\n",
      "Epoch 475/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9239 - loss: 0.2345 - val_accuracy: 0.9432 - val_loss: 0.2201\n",
      "Epoch 476/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9243 - loss: 0.2294 - val_accuracy: 0.9439 - val_loss: 0.2191\n",
      "Epoch 477/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9254 - loss: 0.2247 - val_accuracy: 0.9437 - val_loss: 0.2204\n",
      "Epoch 478/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9253 - loss: 0.2318 - val_accuracy: 0.9438 - val_loss: 0.2220\n",
      "Epoch 479/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9238 - loss: 0.2364 - val_accuracy: 0.9440 - val_loss: 0.2218\n",
      "Epoch 480/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9231 - loss: 0.2356 - val_accuracy: 0.9436 - val_loss: 0.2216\n",
      "Epoch 481/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9241 - loss: 0.2282 - val_accuracy: 0.9436 - val_loss: 0.2193\n",
      "Epoch 482/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9244 - loss: 0.2338 - val_accuracy: 0.9442 - val_loss: 0.2207\n",
      "Epoch 483/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9255 - loss: 0.2308 - val_accuracy: 0.9442 - val_loss: 0.2198\n",
      "Epoch 484/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9259 - loss: 0.2265 - val_accuracy: 0.9429 - val_loss: 0.2196\n",
      "Epoch 485/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9241 - loss: 0.2286 - val_accuracy: 0.9435 - val_loss: 0.2222\n",
      "Epoch 486/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9257 - loss: 0.2246 - val_accuracy: 0.9439 - val_loss: 0.2216\n",
      "Epoch 487/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9217 - loss: 0.2394 - val_accuracy: 0.9438 - val_loss: 0.2231\n",
      "Epoch 488/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9234 - loss: 0.2288 - val_accuracy: 0.9435 - val_loss: 0.2215\n",
      "Epoch 489/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9240 - loss: 0.2291 - val_accuracy: 0.9437 - val_loss: 0.2225\n",
      "Epoch 490/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9242 - loss: 0.2314 - val_accuracy: 0.9432 - val_loss: 0.2225\n",
      "Epoch 491/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9266 - loss: 0.2257 - val_accuracy: 0.9438 - val_loss: 0.2224\n",
      "Epoch 492/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9228 - loss: 0.2331 - val_accuracy: 0.9438 - val_loss: 0.2225\n",
      "Epoch 493/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9232 - loss: 0.2311 - val_accuracy: 0.9443 - val_loss: 0.2230\n",
      "Epoch 494/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9237 - loss: 0.2317 - val_accuracy: 0.9438 - val_loss: 0.2230\n",
      "Epoch 495/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9252 - loss: 0.2275 - val_accuracy: 0.9433 - val_loss: 0.2259\n",
      "Epoch 496/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9232 - loss: 0.2302 - val_accuracy: 0.9442 - val_loss: 0.2237\n",
      "Epoch 497/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9222 - loss: 0.2372 - val_accuracy: 0.9442 - val_loss: 0.2229\n",
      "Epoch 498/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9219 - loss: 0.2385 - val_accuracy: 0.9435 - val_loss: 0.2238\n",
      "Epoch 499/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9239 - loss: 0.2335 - val_accuracy: 0.9427 - val_loss: 0.2245\n",
      "Epoch 500/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9247 - loss: 0.2308 - val_accuracy: 0.9429 - val_loss: 0.2237\n",
      "Epoch 501/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9261 - loss: 0.2242 - val_accuracy: 0.9448 - val_loss: 0.2230\n",
      "Epoch 502/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9243 - loss: 0.2287 - val_accuracy: 0.9437 - val_loss: 0.2244\n",
      "Epoch 503/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9247 - loss: 0.2314 - val_accuracy: 0.9436 - val_loss: 0.2230\n",
      "Epoch 504/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9235 - loss: 0.2337 - val_accuracy: 0.9438 - val_loss: 0.2234\n",
      "Epoch 505/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9249 - loss: 0.2297 - val_accuracy: 0.9435 - val_loss: 0.2244\n",
      "Epoch 506/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9257 - loss: 0.2313 - val_accuracy: 0.9429 - val_loss: 0.2262\n",
      "Epoch 507/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9220 - loss: 0.2329 - val_accuracy: 0.9432 - val_loss: 0.2255\n",
      "Epoch 508/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9248 - loss: 0.2277 - val_accuracy: 0.9436 - val_loss: 0.2231\n",
      "Epoch 509/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9232 - loss: 0.2335 - val_accuracy: 0.9436 - val_loss: 0.2240\n",
      "Epoch 510/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9256 - loss: 0.2240 - val_accuracy: 0.9438 - val_loss: 0.2246\n",
      "Epoch 511/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9232 - loss: 0.2356 - val_accuracy: 0.9439 - val_loss: 0.2257\n",
      "Epoch 512/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9250 - loss: 0.2291 - val_accuracy: 0.9438 - val_loss: 0.2268\n",
      "Epoch 513/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9221 - loss: 0.2360 - val_accuracy: 0.9442 - val_loss: 0.2248\n",
      "Epoch 514/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9246 - loss: 0.2305 - val_accuracy: 0.9438 - val_loss: 0.2264\n",
      "Epoch 515/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9244 - loss: 0.2303 - val_accuracy: 0.9437 - val_loss: 0.2249\n",
      "Epoch 516/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9254 - loss: 0.2299 - val_accuracy: 0.9429 - val_loss: 0.2272\n",
      "Epoch 517/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9252 - loss: 0.2256 - val_accuracy: 0.9428 - val_loss: 0.2277\n",
      "Epoch 518/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.2312 - val_accuracy: 0.9440 - val_loss: 0.2269\n",
      "Epoch 519/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9226 - loss: 0.2353 - val_accuracy: 0.9430 - val_loss: 0.2247\n",
      "Epoch 520/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9221 - loss: 0.2312 - val_accuracy: 0.9432 - val_loss: 0.2251\n",
      "Epoch 521/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9225 - loss: 0.2341 - val_accuracy: 0.9432 - val_loss: 0.2268\n",
      "Epoch 522/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9242 - loss: 0.2238 - val_accuracy: 0.9435 - val_loss: 0.2264\n",
      "Epoch 523/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9233 - loss: 0.2343 - val_accuracy: 0.9433 - val_loss: 0.2281\n",
      "Epoch 524/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9264 - loss: 0.2233 - val_accuracy: 0.9433 - val_loss: 0.2271\n",
      "Epoch 525/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9257 - loss: 0.2214 - val_accuracy: 0.9438 - val_loss: 0.2260\n",
      "Epoch 526/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9261 - loss: 0.2223 - val_accuracy: 0.9429 - val_loss: 0.2285\n",
      "Epoch 527/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9246 - loss: 0.2263 - val_accuracy: 0.9427 - val_loss: 0.2282\n",
      "Epoch 528/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9247 - loss: 0.2311 - val_accuracy: 0.9424 - val_loss: 0.2272\n",
      "Epoch 529/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9254 - loss: 0.2296 - val_accuracy: 0.9435 - val_loss: 0.2270\n",
      "Epoch 530/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9264 - loss: 0.2286 - val_accuracy: 0.9438 - val_loss: 0.2284\n",
      "Epoch 531/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9241 - loss: 0.2290 - val_accuracy: 0.9422 - val_loss: 0.2266\n",
      "Epoch 532/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9242 - loss: 0.2255 - val_accuracy: 0.9437 - val_loss: 0.2268\n",
      "Epoch 533/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9252 - loss: 0.2271 - val_accuracy: 0.9421 - val_loss: 0.2313\n",
      "Epoch 534/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9227 - loss: 0.2309 - val_accuracy: 0.9428 - val_loss: 0.2275\n",
      "Epoch 535/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9235 - loss: 0.2299 - val_accuracy: 0.9426 - val_loss: 0.2276\n",
      "Epoch 536/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.2272 - val_accuracy: 0.9433 - val_loss: 0.2278\n",
      "Epoch 537/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9246 - loss: 0.2288 - val_accuracy: 0.9430 - val_loss: 0.2290\n",
      "Epoch 538/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9243 - loss: 0.2298 - val_accuracy: 0.9433 - val_loss: 0.2288\n",
      "Epoch 539/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9244 - loss: 0.2261 - val_accuracy: 0.9432 - val_loss: 0.2288\n",
      "Epoch 540/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.2273 - val_accuracy: 0.9428 - val_loss: 0.2291\n",
      "Epoch 541/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9256 - loss: 0.2263 - val_accuracy: 0.9427 - val_loss: 0.2286\n",
      "Epoch 542/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9255 - loss: 0.2256 - val_accuracy: 0.9430 - val_loss: 0.2297\n",
      "Epoch 543/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9242 - loss: 0.2273 - val_accuracy: 0.9434 - val_loss: 0.2288\n",
      "Epoch 544/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9230 - loss: 0.2304 - val_accuracy: 0.9436 - val_loss: 0.2279\n",
      "Epoch 545/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9226 - loss: 0.2327 - val_accuracy: 0.9427 - val_loss: 0.2298\n",
      "Epoch 546/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9238 - loss: 0.2280 - val_accuracy: 0.9440 - val_loss: 0.2289\n",
      "Epoch 547/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9233 - loss: 0.2274 - val_accuracy: 0.9431 - val_loss: 0.2295\n",
      "Epoch 548/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9247 - loss: 0.2262 - val_accuracy: 0.9425 - val_loss: 0.2302\n",
      "Epoch 549/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9288 - loss: 0.2172 - val_accuracy: 0.9429 - val_loss: 0.2297\n",
      "Epoch 550/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9235 - loss: 0.2311 - val_accuracy: 0.9426 - val_loss: 0.2299\n",
      "Epoch 551/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9244 - loss: 0.2308 - val_accuracy: 0.9427 - val_loss: 0.2302\n",
      "Epoch 552/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9242 - loss: 0.2282 - val_accuracy: 0.9431 - val_loss: 0.2317\n",
      "Epoch 553/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9242 - loss: 0.2292 - val_accuracy: 0.9428 - val_loss: 0.2312\n",
      "Epoch 554/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9244 - loss: 0.2284 - val_accuracy: 0.9417 - val_loss: 0.2339\n",
      "Epoch 555/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9256 - loss: 0.2268 - val_accuracy: 0.9422 - val_loss: 0.2309\n",
      "Epoch 556/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9231 - loss: 0.2286 - val_accuracy: 0.9428 - val_loss: 0.2299\n",
      "Epoch 557/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9245 - loss: 0.2300 - val_accuracy: 0.9423 - val_loss: 0.2296\n",
      "Epoch 558/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9241 - loss: 0.2280 - val_accuracy: 0.9427 - val_loss: 0.2330\n",
      "Epoch 559/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9266 - loss: 0.2216 - val_accuracy: 0.9426 - val_loss: 0.2300\n",
      "Epoch 560/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9268 - loss: 0.2199 - val_accuracy: 0.9420 - val_loss: 0.2321\n",
      "Epoch 561/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9256 - loss: 0.2256 - val_accuracy: 0.9430 - val_loss: 0.2320\n",
      "Epoch 562/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9257 - loss: 0.2249 - val_accuracy: 0.9434 - val_loss: 0.2295\n",
      "Epoch 563/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9223 - loss: 0.2319 - val_accuracy: 0.9431 - val_loss: 0.2314\n",
      "Epoch 564/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9244 - loss: 0.2321 - val_accuracy: 0.9435 - val_loss: 0.2324\n",
      "Epoch 565/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9257 - loss: 0.2267 - val_accuracy: 0.9424 - val_loss: 0.2327\n",
      "Epoch 566/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9260 - loss: 0.2240 - val_accuracy: 0.9442 - val_loss: 0.2319\n",
      "Epoch 567/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9271 - loss: 0.2237 - val_accuracy: 0.9433 - val_loss: 0.2330\n",
      "Epoch 568/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9237 - loss: 0.2265 - val_accuracy: 0.9430 - val_loss: 0.2310\n",
      "Epoch 569/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9212 - loss: 0.2353 - val_accuracy: 0.9427 - val_loss: 0.2321\n",
      "Epoch 570/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9280 - loss: 0.2195 - val_accuracy: 0.9433 - val_loss: 0.2311\n",
      "Epoch 571/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9280 - loss: 0.2182 - val_accuracy: 0.9427 - val_loss: 0.2324\n",
      "Epoch 572/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9267 - loss: 0.2237 - val_accuracy: 0.9427 - val_loss: 0.2307\n",
      "Epoch 573/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9254 - loss: 0.2263 - val_accuracy: 0.9428 - val_loss: 0.2315\n",
      "Epoch 574/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9256 - loss: 0.2271 - val_accuracy: 0.9427 - val_loss: 0.2318\n",
      "Epoch 575/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9237 - loss: 0.2266 - val_accuracy: 0.9438 - val_loss: 0.2313\n",
      "Epoch 576/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9266 - loss: 0.2227 - val_accuracy: 0.9420 - val_loss: 0.2344\n",
      "Epoch 577/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9252 - loss: 0.2281 - val_accuracy: 0.9432 - val_loss: 0.2325\n",
      "Epoch 578/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9252 - loss: 0.2242 - val_accuracy: 0.9423 - val_loss: 0.2340\n",
      "Epoch 579/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9259 - loss: 0.2247 - val_accuracy: 0.9423 - val_loss: 0.2335\n",
      "Epoch 580/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9263 - loss: 0.2237 - val_accuracy: 0.9427 - val_loss: 0.2335\n",
      "Epoch 581/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9281 - loss: 0.2232 - val_accuracy: 0.9435 - val_loss: 0.2329\n",
      "Epoch 582/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9242 - loss: 0.2309 - val_accuracy: 0.9426 - val_loss: 0.2351\n",
      "Epoch 583/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9248 - loss: 0.2267 - val_accuracy: 0.9429 - val_loss: 0.2351\n",
      "Epoch 584/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9253 - loss: 0.2236 - val_accuracy: 0.9417 - val_loss: 0.2345\n",
      "Epoch 585/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9237 - loss: 0.2278 - val_accuracy: 0.9425 - val_loss: 0.2335\n",
      "Epoch 586/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9241 - loss: 0.2293 - val_accuracy: 0.9430 - val_loss: 0.2345\n",
      "Epoch 587/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9255 - loss: 0.2229 - val_accuracy: 0.9431 - val_loss: 0.2334\n",
      "Epoch 588/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9257 - loss: 0.2230 - val_accuracy: 0.9424 - val_loss: 0.2338\n",
      "Epoch 589/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9254 - loss: 0.2260 - val_accuracy: 0.9423 - val_loss: 0.2344\n",
      "Epoch 590/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9232 - loss: 0.2283 - val_accuracy: 0.9428 - val_loss: 0.2334\n",
      "Epoch 591/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9270 - loss: 0.2239 - val_accuracy: 0.9423 - val_loss: 0.2335\n",
      "Epoch 592/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9240 - loss: 0.2284 - val_accuracy: 0.9428 - val_loss: 0.2346\n",
      "Epoch 593/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9267 - loss: 0.2216 - val_accuracy: 0.9430 - val_loss: 0.2358\n",
      "Epoch 594/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9235 - loss: 0.2291 - val_accuracy: 0.9424 - val_loss: 0.2342\n",
      "Epoch 595/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9246 - loss: 0.2310 - val_accuracy: 0.9427 - val_loss: 0.2342\n",
      "Epoch 596/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9247 - loss: 0.2238 - val_accuracy: 0.9426 - val_loss: 0.2344\n",
      "Epoch 597/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9249 - loss: 0.2248 - val_accuracy: 0.9422 - val_loss: 0.2341\n",
      "Epoch 598/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9268 - loss: 0.2244 - val_accuracy: 0.9428 - val_loss: 0.2347\n",
      "Epoch 599/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9282 - loss: 0.2168 - val_accuracy: 0.9428 - val_loss: 0.2342\n",
      "Epoch 600/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9252 - loss: 0.2241 - val_accuracy: 0.9424 - val_loss: 0.2345\n",
      "Epoch 601/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9256 - loss: 0.2244 - val_accuracy: 0.9418 - val_loss: 0.2364\n",
      "Epoch 602/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9268 - loss: 0.2249 - val_accuracy: 0.9428 - val_loss: 0.2367\n",
      "Epoch 603/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9241 - loss: 0.2313 - val_accuracy: 0.9423 - val_loss: 0.2361\n",
      "Epoch 604/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9277 - loss: 0.2193 - val_accuracy: 0.9425 - val_loss: 0.2346\n",
      "Epoch 605/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9237 - loss: 0.2254 - val_accuracy: 0.9427 - val_loss: 0.2358\n",
      "Epoch 606/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9236 - loss: 0.2286 - val_accuracy: 0.9426 - val_loss: 0.2370\n",
      "Epoch 607/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9270 - loss: 0.2225 - val_accuracy: 0.9417 - val_loss: 0.2377\n",
      "Epoch 608/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9246 - loss: 0.2255 - val_accuracy: 0.9423 - val_loss: 0.2372\n",
      "Epoch 609/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9259 - loss: 0.2320 - val_accuracy: 0.9423 - val_loss: 0.2388\n",
      "Epoch 610/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9253 - loss: 0.2302 - val_accuracy: 0.9424 - val_loss: 0.2355\n",
      "Epoch 611/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9273 - loss: 0.2201 - val_accuracy: 0.9423 - val_loss: 0.2373\n",
      "Epoch 612/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9269 - loss: 0.2203 - val_accuracy: 0.9426 - val_loss: 0.2385\n",
      "Epoch 613/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9266 - loss: 0.2214 - val_accuracy: 0.9433 - val_loss: 0.2346\n",
      "Epoch 614/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9251 - loss: 0.2273 - val_accuracy: 0.9427 - val_loss: 0.2370\n",
      "Epoch 615/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9269 - loss: 0.2241 - val_accuracy: 0.9417 - val_loss: 0.2383\n",
      "Epoch 616/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9266 - loss: 0.2210 - val_accuracy: 0.9418 - val_loss: 0.2385\n",
      "Epoch 617/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9258 - loss: 0.2266 - val_accuracy: 0.9420 - val_loss: 0.2381\n",
      "Epoch 618/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9271 - loss: 0.2181 - val_accuracy: 0.9427 - val_loss: 0.2358\n",
      "Epoch 619/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9244 - loss: 0.2271 - val_accuracy: 0.9421 - val_loss: 0.2373\n",
      "Epoch 620/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9251 - loss: 0.2270 - val_accuracy: 0.9416 - val_loss: 0.2388\n",
      "Epoch 621/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9252 - loss: 0.2271 - val_accuracy: 0.9421 - val_loss: 0.2381\n",
      "Epoch 622/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9253 - loss: 0.2260 - val_accuracy: 0.9416 - val_loss: 0.2388\n",
      "Epoch 623/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9259 - loss: 0.2226 - val_accuracy: 0.9423 - val_loss: 0.2396\n",
      "Epoch 624/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9264 - loss: 0.2232 - val_accuracy: 0.9423 - val_loss: 0.2396\n",
      "Epoch 625/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9276 - loss: 0.2181 - val_accuracy: 0.9428 - val_loss: 0.2377\n",
      "Epoch 626/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9250 - loss: 0.2271 - val_accuracy: 0.9423 - val_loss: 0.2402\n",
      "Epoch 627/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9276 - loss: 0.2196 - val_accuracy: 0.9429 - val_loss: 0.2387\n",
      "Epoch 628/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9247 - loss: 0.2282 - val_accuracy: 0.9416 - val_loss: 0.2386\n",
      "Epoch 629/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9249 - loss: 0.2279 - val_accuracy: 0.9423 - val_loss: 0.2390\n",
      "Epoch 630/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9236 - loss: 0.2244 - val_accuracy: 0.9427 - val_loss: 0.2389\n",
      "Epoch 631/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9261 - loss: 0.2291 - val_accuracy: 0.9423 - val_loss: 0.2414\n",
      "Epoch 632/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9251 - loss: 0.2280 - val_accuracy: 0.9426 - val_loss: 0.2397\n",
      "Epoch 633/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9245 - loss: 0.2313 - val_accuracy: 0.9425 - val_loss: 0.2370\n",
      "Epoch 634/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9262 - loss: 0.2246 - val_accuracy: 0.9427 - val_loss: 0.2390\n",
      "Epoch 635/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9257 - loss: 0.2255 - val_accuracy: 0.9416 - val_loss: 0.2404\n",
      "Epoch 636/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9226 - loss: 0.2354 - val_accuracy: 0.9417 - val_loss: 0.2394\n",
      "Epoch 637/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9246 - loss: 0.2243 - val_accuracy: 0.9428 - val_loss: 0.2398\n",
      "Epoch 638/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9245 - loss: 0.2208 - val_accuracy: 0.9421 - val_loss: 0.2383\n",
      "Epoch 639/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9249 - loss: 0.2270 - val_accuracy: 0.9420 - val_loss: 0.2403\n",
      "Epoch 640/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9264 - loss: 0.2240 - val_accuracy: 0.9411 - val_loss: 0.2403\n",
      "Epoch 641/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9247 - loss: 0.2302 - val_accuracy: 0.9423 - val_loss: 0.2409\n",
      "Epoch 642/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9274 - loss: 0.2205 - val_accuracy: 0.9418 - val_loss: 0.2428\n",
      "Epoch 643/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9250 - loss: 0.2270 - val_accuracy: 0.9422 - val_loss: 0.2414\n",
      "Epoch 644/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9283 - loss: 0.2162 - val_accuracy: 0.9426 - val_loss: 0.2412\n",
      "Epoch 645/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9250 - loss: 0.2249 - val_accuracy: 0.9418 - val_loss: 0.2416\n",
      "Epoch 646/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9241 - loss: 0.2289 - val_accuracy: 0.9421 - val_loss: 0.2418\n",
      "Epoch 647/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9272 - loss: 0.2219 - val_accuracy: 0.9422 - val_loss: 0.2401\n",
      "Epoch 648/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9267 - loss: 0.2246 - val_accuracy: 0.9417 - val_loss: 0.2409\n",
      "Epoch 649/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9268 - loss: 0.2222 - val_accuracy: 0.9425 - val_loss: 0.2419\n",
      "Epoch 650/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9261 - loss: 0.2271 - val_accuracy: 0.9419 - val_loss: 0.2407\n",
      "Epoch 651/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9250 - loss: 0.2259 - val_accuracy: 0.9412 - val_loss: 0.2406\n",
      "Epoch 652/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9264 - loss: 0.2264 - val_accuracy: 0.9417 - val_loss: 0.2406\n",
      "Epoch 653/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9245 - loss: 0.2300 - val_accuracy: 0.9414 - val_loss: 0.2399\n",
      "Epoch 654/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9272 - loss: 0.2224 - val_accuracy: 0.9422 - val_loss: 0.2395\n",
      "Epoch 655/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9254 - loss: 0.2223 - val_accuracy: 0.9423 - val_loss: 0.2401\n",
      "Epoch 656/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9261 - loss: 0.2213 - val_accuracy: 0.9422 - val_loss: 0.2430\n",
      "Epoch 657/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9227 - loss: 0.2261 - val_accuracy: 0.9417 - val_loss: 0.2401\n",
      "Epoch 658/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9267 - loss: 0.2196 - val_accuracy: 0.9412 - val_loss: 0.2422\n",
      "Epoch 659/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9280 - loss: 0.2177 - val_accuracy: 0.9414 - val_loss: 0.2408\n",
      "Epoch 660/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9232 - loss: 0.2295 - val_accuracy: 0.9409 - val_loss: 0.2449\n",
      "Epoch 661/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9273 - loss: 0.2211 - val_accuracy: 0.9415 - val_loss: 0.2416\n",
      "Epoch 662/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9241 - loss: 0.2273 - val_accuracy: 0.9406 - val_loss: 0.2478\n",
      "Epoch 663/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9247 - loss: 0.2264 - val_accuracy: 0.9418 - val_loss: 0.2439\n",
      "Epoch 664/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9271 - loss: 0.2181 - val_accuracy: 0.9422 - val_loss: 0.2433\n",
      "Epoch 665/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9250 - loss: 0.2255 - val_accuracy: 0.9423 - val_loss: 0.2442\n",
      "Epoch 666/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9263 - loss: 0.2247 - val_accuracy: 0.9422 - val_loss: 0.2433\n",
      "Epoch 667/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9275 - loss: 0.2194 - val_accuracy: 0.9423 - val_loss: 0.2430\n",
      "Epoch 668/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9247 - loss: 0.2232 - val_accuracy: 0.9418 - val_loss: 0.2460\n",
      "Epoch 669/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9273 - loss: 0.2228 - val_accuracy: 0.9418 - val_loss: 0.2437\n",
      "Epoch 670/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9254 - loss: 0.2252 - val_accuracy: 0.9429 - val_loss: 0.2420\n",
      "Epoch 671/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9274 - loss: 0.2236 - val_accuracy: 0.9415 - val_loss: 0.2434\n",
      "Epoch 672/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9279 - loss: 0.2198 - val_accuracy: 0.9419 - val_loss: 0.2426\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, epochs =1000, validation_split =0.20, batch_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e33f82-17fb-4066-9ccc-ad8f63156abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc122226-4dea-4a58-842c-d274bd0ff54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_prob.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529072bc-b2b6-4307-a26e-b1951355fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe967e9-2db6-496d-8da4-9090a972953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,y_test)\n",
    "print('accuracy :',test_acc)\n",
    "print('loss :',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bfdd69-c5e2-4881-b570-e659e026aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'] , label = 'loss')\n",
    "plt.plot(hist.history['val_loss'], label = 'val_loss')\n",
    "plt.title('LOSS')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199623f1-9aaf-4430-9500-099adaca136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['accuracy'], label = 'accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.title('ACCURACY')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c83203b-20ca-47e3-be20-1f8d1faadfbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
